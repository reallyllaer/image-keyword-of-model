{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec 하이퍼파라미터 튜닝\n",
        "- vector_size 1~300까지 확인하며, 어떤 벡터 사이즈가 가장 정확한 유사도를 도출하는지 확인 시도\n",
        "- 1) train, test 인물 키워드 top 20 중 BPS 5개 척도중 하나에 명확히 포함되는 키워드들을 condition으로 정의\n",
        "- 2) condition들을 가장 많이 만족하는 벡터 사이즈 순위 도출"
      ],
      "metadata": {
        "id": "hJ4q5XTmzXX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- train 데이터 : 벡터 사이즈 변화에 따른 Word2Vec 유사도"
      ],
      "metadata": {
        "id": "ScMka5JZ0S1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_calculate_similarity(vector_size):\n",
        "    docs = [train_top20_keywords] + [sincerity] + [excitement] + [competence] + [sophistication] + [ruggedness]\n",
        "    model = Word2Vec(sentences=docs, vector_size=vector_size, window=4, hs=1, negative=0, min_count=1, sg=1)\n",
        "\n",
        "    train_result = []\n",
        "    for keyword in train_top20_keywords:\n",
        "        columns = {'벡터 사이즈': vector_size, 'top20 키워드': keyword}  # 벡터 사이즈와 키워드 추가\n",
        "        for category, words in [('진실성', sincerity),\n",
        "                                ('흥미로움', excitement),\n",
        "                                ('유능함', competence),\n",
        "                                ('세련됨', sophistication),\n",
        "                                ('강인함', ruggedness)]:\n",
        "            sim_sum = sum(model.wv.similarity(w1=keyword, w2=word) for word in words)\n",
        "            columns[category] = sim_sum / len(words)\n",
        "\n",
        "        # 가장 유사도가 높은 단어 찾기\n",
        "        max_category = max(category for category in columns.keys() if category != '벡터 사이즈' and category != 'top20 키워드' and isinstance(columns[category], (float, int)) and columns[category] == max(v for k, v in columns.items() if isinstance(v, (float))))\n",
        "        columns['가장 유사한 단어'] = max_category\n",
        "\n",
        "        train_result.append(columns)\n",
        "\n",
        "    return pd.DataFrame(train_result)\n"
      ],
      "metadata": {
        "id": "o2-pW04GzyXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dfs = []\n",
        "for vector_size in range(1, 300, 1):\n",
        "    result_df = train_calculate_similarity(vector_size)\n",
        "    result_dfs.append(result_df)\n",
        "\n",
        "# 결과 데이터프레임들을 하나로 합치기\n",
        "train_final_result = pd.concat(result_dfs, ignore_index=True)\n",
        "\n",
        "# 결과 출력\n",
        "pd.DataFrame(train_final_result)"
      ],
      "metadata": {
        "id": "Or918c4GzyQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- test 데이터 : 벡터 사이즈 변화에 따른 Word2Vec 유사도\n",
        "\n"
      ],
      "metadata": {
        "id": "837YaZmQ0ivt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_calculate_similarity(vector_size):\n",
        "    docs = [test_top20_keywords] + [sincerity] + [excitement] + [competence] + [sophistication] + [ruggedness]\n",
        "    model = Word2Vec(sentences=docs, vector_size=vector_size, window=4, hs=1, negative=0, min_count=1, sg=1)\n",
        "\n",
        "    test_result = []\n",
        "    for keyword in test_top20_keywords:\n",
        "        columns = {'벡터 사이즈': vector_size, 'top20 키워드': keyword}  # 벡터 사이즈와 키워드 추가\n",
        "        for category, words in [('진실성', sincerity),\n",
        "                                ('흥미로움', excitement),\n",
        "                                ('유능함', competence),\n",
        "                                ('세련됨', sophistication),\n",
        "                                ('강인함', ruggedness)]:\n",
        "            sim_sum = sum(model.wv.similarity(w1=keyword, w2=word) for word in words)\n",
        "            columns[category] = sim_sum / len(words)\n",
        "\n",
        "        # 가장 유사도가 높은 단어 찾기\n",
        "        max_category = max(category for category in columns.keys() if category != '벡터 사이즈' and category != 'top20 키워드' and isinstance(columns[category], (float, int)) and columns[category] == max(v for k, v in columns.items() if isinstance(v, (float))))\n",
        "        columns['가장 유사한 단어'] = max_category\n",
        "\n",
        "        test_result.append(columns)\n",
        "\n",
        "    return pd.DataFrame(test_result)"
      ],
      "metadata": {
        "id": "Ivvo_n8jzyMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dfs = []\n",
        "for vector_size in range(1, 300, 1):\n",
        "    result_df = test_calculate_similarity(vector_size)\n",
        "    result_dfs.append(result_df)\n",
        "\n",
        "# 결과 데이터프레임들을 하나로 합치기\n",
        "test_final_result = pd.concat(result_dfs, ignore_index=True)\n",
        "\n",
        "# 결과 출력\n",
        "pd.DataFrame(test_final_result)"
      ],
      "metadata": {
        "id": "njNr79cazxvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- train 데이터 : 특정 조건 만족 벡터사이즈 top 10 확인"
      ],
      "metadata": {
        "id": "loidDbBl1rnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 조건을 만족하는 행들을 필터링하여 추출\n",
        "condition1 = (train_final_result['top20 키워드'] == '솔직함') & (train_final_result['가장 유사한 단어'] == '진실성')\n",
        "condition2 = (train_final_result['top20 키워드'] == '색다름') & (train_final_result['가장 유사한 단어'] == '흥미로움')\n",
        "condition3 = (train_final_result['top20 키워드'] == '신선함') & (train_final_result['가장 유사한 단어'] == '흥미로움')\n",
        "condition4 = (train_final_result['top20 키워드'] == '화려함') & (train_final_result['가장 유사한 단어'] == '세련됨')\n",
        "\n",
        "filtered_df = train_final_result[condition1 | condition2 | condition3 | condition4 ]\n",
        "\n",
        "# 카운트를 기준으로 내림차순 정렬하여 상위 10개 벡터 사이즈 추출\n",
        "top_vector_sizes = vector_size_counts.sort_values(ascending=False).head(10).index\n",
        "\n",
        "# 필터링된 결과에서 '벡터 사이즈'와 해당 카테고리의 유사도 점수 추출\n",
        "train_selected_data = filtered_df[filtered_df['벡터 사이즈'].isin(top_vector_sizes)]\n",
        "\n",
        "# 결과 출력\n",
        "print(train_selected_data['벡터 사이즈'].value_counts())"
      ],
      "metadata": {
        "id": "2ZDAAEPt0xE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- test 데이터 : 특정 조건 만족 벡터사이즈 top 10 확인"
      ],
      "metadata": {
        "id": "aXCE1yFv0yZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition1 = (test_final_result['top20 키워드'] == '다채함') & (test_final_result['가장 유사한 단어'] == '흥미로움')\n",
        "condition2 = (test_final_result['top20 키워드'] == '독특함') & (test_final_result['가장 유사한 단어'] == '흥미로움')\n",
        "condition3 = (test_final_result['top20 키워드'] == '우아함') & (test_final_result['가장 유사한 단어'] == '세련됨')\n",
        "condition4 = (test_final_result['top20 키워드'] == '강함') & (test_final_result['가장 유사한 단어'] == '강인함')\n",
        "\n",
        "filtered_df = final_result[condition1 | condition2 | condition3 | condition4 ]\n",
        "\n",
        "# 필터링된 결과에서 '벡터 사이즈' 별로 카운트 계산\n",
        "vector_size_counts = filtered_df['벡터 사이즈'].value_counts()\n",
        "\n",
        "# 카운트를 기준으로 내림차순 정렬하여 상위 10개 벡터 사이즈 추출\n",
        "top_vector_sizes = vector_size_counts.sort_values(ascending=False).head(10).index\n",
        "\n",
        "# 상위 벡터 사이즈에 해당하는 데이터 추출\n",
        "test_selected_data = filtered_df[filtered_df['벡터 사이즈'].isin(top_vector_sizes)]\n",
        "\n",
        "# 결과 출력\n",
        "print(test_selected_data['벡터 사이즈'].value_counts())"
      ],
      "metadata": {
        "id": "6Bft9q8o0xfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}